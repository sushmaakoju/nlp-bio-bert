# -*- coding: utf-8 -*-
"""BIO-tag-CustomNERwithSpacy_homework.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cuetjKF8-ZH6guq6gtDKeIbIAU9Agx3b

### Named Entity Recognition for I, B tags with Spacy's en_core_web_sm model to train and predict over biomedical journal corpus

##### Homework 3, Fall, 2021
##### Prof. James H. Martin
###### author: Sushma Akoju

#### Named Entity Recognition over medical journal corpus
Required features:
  - Sentence id
  - Word
  - POS
  - Tag

#### Goal: 
The task in homework suggests to detect “Gene” entities which could appear in patterns such as “BII”, “BIO”, or even regex such as “BI[I]*[O]*”.

#### Reference
[Custom NER task using SPACY:]( https://www.youtube.com/watch?v=DxLcMI-EMYI )

#### Intuition/background for this approach:
##### Given that NER task analysis based on results from IB tag sequence approach, the next natural assumption is to include O tag nevertheless.
"""

#Import all required libraries
import spacy
import random
import time
import numpy as np
from spacy.util import minibatch, compounding
import sys
from spacy import displacy
from itertools import chain
import matplotlib.pyplot as plt 
from matplotlib.ticker import MaxNLocator

from google.colab import drive
drive.mount('/content/drive')

import os
os.path.exists('/content/drive/MyDrive/Colab Notebooks/entity-extraction/hw3/train.tsv')

file = open("/content/drive/MyDrive/Colab Notebooks/entity-extraction/hw3/train.tsv", 'r',  newline="\n")
counter = 0
for line in file:
  #print(line)
  l = line.strip().split("\t")
  #print(l)
  #if len(l)>1:
    #print(l[0:],l[1].strip(),l[0].strip())
  if len(l)<=1:
    #print("new line")
    counter += 1
print(counter)

"""We have to convert tsv file to the format accepted by spaCy for training.
One of the format supported by spaCy is:
TRAIN_DATA = [[(Sentence, {entities: [(start, end, label)]], ...]
"""

def load_data_spacy(file_path):
    ''' Converts data from:
    word \t label \n word \t label \n \n word \t label
    to: sentence, {entities : [(start, end, label), (stard, end, label)]}
    '''
    file = open(file_path, 'r', encoding="utf8", newline="\n")
    training_data, entities, sentence = [], [], []
    unique_labels = []
    current_annotation = None
    start =0
    end = 0 # initialize counter to keep track of start and end characters
    lines = file.readlines()
    for line in lines:
        #print(line)
        line = [l.strip() for l in line.strip().split("\t")[1:]]
        # lines with len > 1 are words
        #print(line)
        if len(line) > 1:
            label = line[1].strip()
            #print(label)
            if label == '1':
              print(line[0])
              label = 'I'

            # if(label != 'O'):
            #   if line[1].strip() == '1':
            #     label = 'I'
            #   else:
            #     label = line[1].strip()
                #label = line[1].strip()    # the .txt is formatted: label \t word, label[0:2] = label_type
            #label_type = line[0][0] # beginning of annotations - "B", intermediate - "I"
            word = line[0].strip()
            
            sentence.append(word)
            start = end
            end += (len(word) + 1)  # length of the word + trailing space
                              
            if label == 'B':                         # if beginning new annotation
                entities.append(( start,end-1, label))# start annotation at beginning of word
            #print(entities)
            if label == 'I' :  # if at the end of an annotation
                #print(word, label)
                entities.append(( start,end-1, label))  # append the annotation
            if label == 'O' :  # if at the end of an annotation
                #print(word, label)
                entities.append(( start,end-1, label))  # append the annotation                  
           
            if label not in unique_labels:
                unique_labels.append(label)
            
        # lines with len == 1 are breaks between sentences
        if len(line) <=1:#line[0].strip() =='' and line[1].strip()== '':
            #print(line)
            if(len(entities) > 0):
                sentence = " ".join(sentence)
                training_data.append([sentence, {'entities' : entities}])
            # reset the counters and temporary lists
            end = 0 
            start = 0
            entities, sentence = [], []
            
    file.close()
    print(training_data, unique_labels)
    return training_data, unique_labels

"""Let us convert our train data,test data and validation data to spaCy format"""

TRAIN_DATA, LABELS = load_data_spacy("/content/drive/MyDrive/Colab Notebooks/entity-extraction/hw3/train.tsv")
print(TRAIN_DATA)

print(LABELS), len(TRAIN_DATA)

TRAIN_DATA, LABELS = load_data_spacy("/content/drive/MyDrive/Colab Notebooks/entity-extraction/hw3/train.tsv")
print(len(TRAIN_DATA))
TEST_DATA, _ = load_data_spacy("/content/drive/MyDrive/Colab Notebooks/entity-extraction/hw3/test.tsv")
print(len(TEST_DATA))
VALID_DATA, _ = load_data_spacy("/content/drive/MyDrive/Colab Notebooks/entity-extraction/hw3/train_dev.tsv")
print(len(VALID_DATA))

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Colab Notebooks/entity-extraction/hw3

"""Let us define methods to compute Precision,Recall and F1-score

Model evaluation -> Dataset( train/test/validation)

TP = Word predicted as either I_Disease or B_Disease and present in the data(train/test/validation) as as either I_Disease or B_Disease
FP = Word predicted as either I_Disease or B_Disease and not present in the data (train/test/validation)  as as either I_Disease or B_Disease
FN = Word present in the data(train/test/validation) data as as either I_Disease or B_Disease but not predicted as as either I_Disease or B_Disease

Metrics:
Precision = TP/(TP+FP )
Recall = TP/(TP+FN)
F1-score = 2 * Precision* Recall/ (Precision+Recall)
"""

def calc_precision(pred, true):        
    precision = len([x for x in pred if x in true]) / (len(pred) + 1e-20) # true positives / total pred
    return precision

def calc_recall(pred, true):
    recall = len([x for x in true if x in pred]) / (len(true) + 1e-20)    # true positives / total test
    return recall

def calc_f1(precision, recall):
    f1 = 2 * ((precision * recall) / (precision + recall + 1e-20))
    return f1

"""Let us define a method to evaluate our named entity recognition model"""

# run the predictions on each sentence in the evaluation  dataset, and return the metrics
def evaluate(ner, data ):
    preds = [ner(x[0]) for x in data]

    precisions, recalls, f1s = [], [], []

    # iterate over predictions and test data and calculate precision, recall, and F1-score
    for pred, true in zip(preds, data):
        true = [x[2] for x in list(chain.from_iterable(true[1].values()))] # x[2] = annotation, true[1] = (start, end, annot)
        pred = [i.label_ for i in pred.ents] # i.label_ = annotation label, pred.ents = list of annotations
        precision = calc_precision(true, pred)
        precisions.append(precision)
        recall = calc_recall(true, pred)
        recalls.append(recall)
        f1s.append(calc_f1(precision, recall))

    #print("Precision: {} \nRecall: {} \nF1-score: {}".format(np.around(np.mean(precisions), 3),np.around(np.mean(recalls), 3),
    #                                                         np.around(np.mean(f1s), 3)))
    return {"textcat_p": np.mean(precisions), "textcat_r": np.mean(recalls), "textcat_f":np.mean(f1s)}

"""Now let us train a custom named entity recognition model in spaCy for detecting Disease entities
We use an existing model "en_core_web_md"( English medium sized model).
This is a CNN model.
This model by deafult has POS tagger, Dependency parser and Named entity recognition functionalities
We only re-train the named entity recognition part of the model.

Dropout is a regularization technique for reducing overfitting in neural networks by preventing complex co-adaptations on training data. ... The term dropout refers to randomly "dropping out", or omitting, units (both hidden and visible) during the training process of a neural network.
In our case if dropout = 0.5 there is a 50% dropping out otmitting units during training process of our model
"""

def train_spacy(train_data, labels, iterations, dropout = 0.5, display_freq = 10):
    ''' Train a spacy NER model, which can be queried against with test data
   
    train_data : training data in the format of (sentence, {entities: [(start, end, label)]})
    labels : a list of unique annotations
    iterations : number of training iterations
    dropout : dropout proportion for training
    display_freq : number of epochs between logging losses to console
    '''
    import spacy.cli 
    spacy.cli.download("en_core_web_md")

    valid_f1scores=[]
    test_f1scores=[]
    nlp = spacy.load("en_core_web_md")
    #nlp = spacy.blank('en')
    if 'ner' not in nlp.pipe_names:
        ner = nlp.create_pipe('ner')
        nlp.add_pipe(ner)
    else:
        ner = nlp.get_pipe("ner")
   
    # Add entity labels to the NER pipeline
    for i in labels:
        ner.add_label(i)

    # Disable other pipelines in SpaCy to only train NER
    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']
    with nlp.disable_pipes(*other_pipes):
        #nlp.vocab.vectors.name = 'spacy_model' # without this, spaCy throws an "unnamed" error
        optimizer = nlp.begin_training()
        for itr in range(iterations):
            random.shuffle(train_data) # shuffle the training data before each iteration
            losses = {}
            batches = minibatch(train_data, size = compounding(16.0, 64.0, 1.5))
            for batch in batches:
                texts, annotations = zip(*batch)
                nlp.update(
                    texts,
                    annotations,
                    drop = dropout,  
                    sgd = optimizer,
                    losses = losses)
            #if itr % display_freq == 0:
            #    print("Iteration {} Loss: {}".format(itr + 1, losses))
            scores = evaluate(nlp,VALID_DATA)
            valid_f1scores.append(scores["textcat_f"])
            print('=======================================')
            print('Iteration = '+str(itr))
            print('Losses = '+str(losses))
            print('===============VALID DATA========================')
            
            print('F1-score = '+str(scores["textcat_f"]))
            print('Precision = '+str(scores["textcat_p"]))
            print('Recall = '+str(scores["textcat_r"]))
            scores = evaluate(nlp,TEST_DATA)
            test_f1scores.append(scores["textcat_f"])
            print('===============TEST DATA========================')
            print('F1-score = '+str(scores["textcat_f"]))
            print('Precision = '+str(scores["textcat_p"]))
            print('Recall = '+str(scores["textcat_r"]))
            print('=======================================')
            
    return nlp,valid_f1scores,test_f1scores

"""Lets train the model on our dataset"""

import matplotlib.pyplot as plt



# Train (and save) the NER model
ner,valid_f1scores,test_f1scores = train_spacy(TRAIN_DATA, LABELS,10)
ner.to_disk("/content/drive/MyDrive/Colab Notebooks/entity-extraction/hw3/hw3_ner_spacy_GloVE_bio")

x=range(0,20)
 
ax = plt.figure().gca()
#...
ax.xaxis.set_major_locator(MaxNLocator(integer=True))
ax.plot(valid_f1scores,label="Validation F1_score")
ax.plot(test_f1scores,label="Test F1_score")
ax.set_xlabel('Iterations')
ax.set_ylabel('F1 score')
ax.legend()
ax.set_title('F1 score vs Iterations for validation and test data')
# naming the x axis 
#ax.xlabel('Iteration') 
# naming the y axis 
#ax.ylabel('F1 score') 
# giving a title to my graph 
#
# show a legend on the plot 
#ax.legend() 
  
# function to show the plot

"""Lets define a method to load our saved model"""

def load_model(model_path):
    ''' Loads a pre-trained model for prediction on new test sentences
   
    model_path : directory of model saved by spacy.to_disk
    '''
    nlp = spacy.blank('en')
    if 'ner' not in nlp.pipe_names:
        ner = nlp.create_pipe('ner')
        nlp.add_pipe(ner)
    ner = nlp.from_disk(model_path)
    return ner

"""Lets test our model on  test data"""

ner = load_model("/content/drive/MyDrive/Colab Notebooks/entity-extraction/hw3/hw3_ner_spacy_GloVE_bio")

predictions = []

test_sentences = [x[0] for x in TEST_DATA] # extract the sentences from [sentence, entity]
for x in test_sentences:
    counter = 1
    this_sentence = x.split()
    doc = ner(x)
    l = {}
    for ent in doc.ents:
        print(ent.text, ent.start_char, ent.end_char, ent.label_)
        l[ent.text] = ent.label_
    for word in this_sentence:
      if word in list(l.keys()):
        predictions.append([counter, word, l[word]])
      else:
        if word.strip() != "" or word.strip() != '/"':
          predictions.append([counter, word, 'O'])
      counter +=1
    predictions.append(["\n"])
    print(predictions)
    displacy.render(doc,jupyter=True, style = "ent")

import pandas as pd
 df = pd.DataFrame.from_records(predictions)
 df.head()

df.to_csv('predictions_bio.csv', sep="\t", header=False, index = False)

ner = load_model("/content/drive/MyDrive/Colab Notebooks/entity-extraction/hw3/hw3_ner_spacy_GloVE_bio")
doc = ner("Selegiline - induced postural hypotension in Parkinson ' s disease : a longitudinal study on the effects of drug withdrawal.The aims of this study were to confirm our previous findings in a separate cohort of patients and to determine the time course of the cardiovascular consequences of stopping selegiline in the expectation that this might shed light on the mechanisms by which the drug causes orthostatic hypotension")
displacy.render(doc,jupyter=True, style = "ent")

