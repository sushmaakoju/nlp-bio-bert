# -*- coding: utf-8 -*-
"""nlp-hw3-bioBERT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pKUKzVUlYfzAJfivct5C0UbrD1OST9uM

### Named Entity Recognition with BioBERT over biomedical journal corpus

##### Homework 3, Fall, 2021
##### Prof. James H. Martin
###### author: Sushma Akoju

Notebook to train/fine-tune a BioBERT model to perform named entity recognition (NER). 

Required features:
  - Sentence id
  - Word
  - POS
  - Tag

For this task, POS tag for this dataset was not available, POS tag generation was done using NLTK library. [Using a NLTK Tagger](https://www.nltk.org/book/ch05.html)

Steps:
* Getting Data
* Training and validating the Model
* Model Inference over Test data

#### Inuition, background: 
A special case to consider, for example, the least common words in dataset provided for this homework, 'K713','hypercholesterolemic','lutein','P69','conference','Talk','Tele','cruciform','TE105'. They are not only least common, they need special domain specific knowledge for subword tokenization, which is very different as well as difficult from that of other common English word tokens. Thus BioBERT makes for a special case and seems more reasonable to explore. This also complies with the fact that domain specific expertise adds additional information required to understand the Named Entity tags and vice versa. The reverse case is : to represent knowledge and “reason” as understood from a given context in a medical journal text corpus, Named entity recognition also serves as a pre-requisite for knowledge mining. To rephrase the reverse case, for domain specific knowledge mining, we need Named Entity recognition as a prerequisite.

#### Task Description

> Named entity recognition (NER) is the task of tagging entities in text with their corresponding type. Approaches typically use BIO notation, which differentiates the beginning (B) and the inside (I) of entities. O is used for non-entity tokens.

#### Install Dependencies and Restart Runtime
"""

!pip install -q transformers
!pip install -q simpletransformers

"""### Getting Data

#### Loading the data from Google Drive
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np

d = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/entity-extraction/hw3/data_ner_hw/bio_ner.csv")
n =  d.to_numpy().tolist()
new_list = []
counter = 0
for l in n:
  #print(l)
  if l[2] == 1:
    counter += 1
  l[1] = counter
  new_list.append(l)

"""##### The data was converted to a csv file with Sentence ID, Line, Word, POS tag and the IOB Tag"""

d = pd.DataFrame.from_records(new_list, columns = ['ind', 'Sentence #','Line','Word', 'POS', 'Tag'])
d.head(30)

d = d.drop('ind', axis=1)
df = d[['Sentence #','Word', 'POS', 'Tag']]
start = df[df['Sentence #']==6897].index.values.astype(int)[0]
second_start = df[df['Sentence #']==10347].index.values.astype(int)[0]
end = df[df['Sentence #']==13794].index.values.astype(int)[0]
train = df.iloc[0:start]
train_dev = df.iloc[start:second_start]
test = df.iloc[second_start:end]

df.head(13)

train.to_csv('/content/drive/MyDrive/Colab Notebooks/entity-extraction/hw3/data_ner_hw/train.tsv', sep="\t", header=False, index = False)
test.to_csv('/content/drive/MyDrive/Colab Notebooks/entity-extraction/hw3/data_ner_hw/test.tsv', sep="\t", header=False, index = False)
train_dev.to_csv('/content/drive/MyDrive/Colab Notebooks/entity-extraction/hw3/data_ner_hw/train_dev.tsv', sep="\t", header=False, index = False)

import pandas as pd
def read_conll(filename):
    df = pd.read_csv(filename,
                    sep = '\t', header = None, keep_default_na = False,
                    names = ['sentence_id','words', 'pos', 'labels'],
                    quoting = 3, skip_blank_lines = False)
    df = df[~df['words'].astype(str).str.startswith('-DOCSTART- ')] 
    return df[df.words != '']

"""#### For this task, Data is split inot Train, Test and Dev datasets.
- Train # : 6896 sentences
- Test # : 3448 sentences.
- Dev # : 3450 sentences.
"""

train_df = read_conll('/content/drive/MyDrive/Colab Notebooks/entity-extraction/hw3/data_ner_hw//train.tsv')
test_df = read_conll('/content/drive/MyDrive/Colab Notebooks/entity-extraction/hw3/data_ner_hw/test.tsv')
dev_df = read_conll('/content/drive/MyDrive/Colab Notebooks/entity-extraction/hw3/data_ner_hw/train_dev.tsv')
test_df.head(20)

"""We now print out the statistics (number of sentences) of the train, dev and test sets."""

data = [[train_df['sentence_id'].nunique(), test_df['sentence_id'].nunique(), dev_df['sentence_id'].nunique()]]

# Prints out the dataset sizes of train and test sets per label.
pd.DataFrame(data, columns=["Train", "Test", "Dev"])

"""# Training and Testing the Model

#### Set up the Training Arguments

We set up the training arguments. Here we train to 10 epochs to get accuracy close to the SOTA. The train, test and dev sets are relatively small so we don't have to wait too long. We set a sliding window as NER sequences can be quite long and because we have limited GPU memory we can't increase the `max_seq_length` too long.
"""

train_args = {
    'reprocess_input_data': True,
    'overwrite_output_dir': True,
    'sliding_window': True,
    'max_seq_length': 64,
    'num_train_epochs': 10,
    'train_batch_size': 32,
    'fp16': True,
    'output_dir': '/outputs/',
    'best_model_dir': '/outputs/best_model/',
    'evaluate_during_training': True,
}

"""The following line of code saves (to the variable `custom_labels`) a set of all the NER tags/labels in the dataset."""

custom_labels = ['I', 'B', 'O'] #list(train_df['labels'].unique())
print(custom_labels)

"""#### Train the Model

###### The pre-trained BioBERT model (by [DMIS Lab, Korea University](https://huggingface.co/dmis-lab)) from the [Hugging Face Transformers](https://github.com/huggingface/transformers) library as the base and use the [Simple Transformers library](https://simpletransformers.ai/docs/classification-models/) on top of it to train the NER (sequence tagging) model with just a few lines of code.
"""

from simpletransformers.ner import NERModel
from transformers import AutoTokenizer
import pandas as pd
import logging

logging.basicConfig(level=logging.DEBUG)
transformers_logger = logging.getLogger('transformers')
transformers_logger.setLevel(logging.WARNING)

# We use the bio BERT pre-trained model.
model = NERModel('bert', 'dmis-lab/biobert-v1.1', labels=custom_labels, args=train_args)

# Train the model
# https://simpletransformers.ai/docs/tips-and-tricks/#using-early-stopping
model.train_model(train_df, eval_data=dev_df)

# Evaluate the model in terms of accuracy score
result, model_outputs, preds_list = model.eval_model(test_df)

"""The F1-score for the model is **84.3%** ('f1_score': 0.8436959490213929).

# Using the Model (Running Inference)

Running the model to do some predictions/inference is as simple as calling `model.predict(samples)`. First we get a sentence from the test set and conduct the prediction of each of the sentence.
"""

ids = test_df.sentence_id.unique().tolist()
len(ids)

preds = []
counter = 1
for id in ids:
  sample = test_df[test_df.sentence_id == id].words.str.cat(sep=' ')
  samples.append(sample)

predictions, _ = model.predict(samples)
print(predictions, samples)
for idx, sample in enumerate(samples):
  counter = 1
  print('{}: '.format(idx))
  for word in predictions[idx]:
    w = list(word.keys())[0]
    tag = list(word.values())[0]
    preds.append([counter, w,tag ])
    print('{}'.format(word), type(word), word)
    counter += 1

df_preds = pd.DataFrame.from_records(preds)
df_preds.head(30)

df_preds.to_csv('/content/drive/MyDrive/Colab Notebooks/entity-extraction/hw3/data_ner_hw/preds_biobert.csv', sep="\t", header=False, index = False)

samples = [sample]
predictions, _ = model.predict(samples)
print(predictions, samples)
for idx, sample in enumerate(samples):
  print('{}: '.format(idx))
  for word in predictions[idx]:
    print('{}'.format(word))

"""You can move the model checkpount files which are saved in the `/outputs/` directory to your Google Drive."""

import shutil
shutil.move('/outputs/', "/content/drive/MyDrive/Colab Notebooks/entity-extraction/hw3/data_ner_hw/outputs/")

"""#### The results and analysis
For comparative purpose, the results and analysis are conducted along with various other approaches implemented for this homework. Additionally, although results from validation do seem impressive, the performance is far apart from expected and/or reasonable f1-scores. The results are covered in detail in final report.
"""